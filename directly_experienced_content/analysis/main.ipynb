{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 14:29:46.111154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Lifelines\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.stats import sem\n",
    "from itertools import groupby\n",
    "import spacy\n",
    "import copy\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "titles = ['Horror', 'Adventure', 'Drama', 'Biography', 'Action', 'Fantasy', 'SciFi', 'Animation']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_lines(ys, title, wtp_mean, wtp_std, mean=False, word=None):\n",
    "    if mean:\n",
    "        ys_mean = np.stack(ys).mean(axis=0)\n",
    "        ys_sem = sem(np.stack(ys), axis=0)\n",
    "    else:\n",
    "        ys_mean = ys\n",
    "\n",
    "    xs = np.linspace(0, 90, num=900)\n",
    "\n",
    "    plt.figure()\n",
    "    poly = np.polyfit(xs, ys_mean, 10)\n",
    "    poly_y = np.poly1d(poly)(xs)\n",
    "    plt.plot(xs, poly_y, color=\"#3da803\", label=\"Smooth\")\n",
    "    plt.plot(xs, ys_mean, color=\"#040dc2\", label=\"Original\")\n",
    "\n",
    "    if mean:\n",
    "        plt.fill_between(xs, ys_mean - ys_sem, ys_mean + ys_sem, alpha=0.2)\n",
    "\n",
    "    plt.title(\"Enjoyment of {} Movie Trailer Over Time\\nWTP M={}, SD={}\".format(title, str(wtp_mean), str(wtp_std)), )\n",
    "\n",
    "    if wtp_std is None:\n",
    "        plt.title(\"WTP = {}, Word = {}\".format(str(wtp_mean), word), fontsize = 25)\n",
    "    else:\n",
    "        plt.ylabel(\"Enjoyment\")\n",
    "        plt.xlabel(\"Time (sec)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    if wtp_std is None:\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        plt.savefig(\"./plots/individual/lifeline_{}.png\".format(title), dpi=50)\n",
    "    else:\n",
    "        plt.savefig(\"./plots/analysis_plots/lifeline_{}.png\".format(title), dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m row\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m title \u001B[38;5;129;01min\u001B[39;00m titles:\n\u001B[0;32m---> 20\u001B[0m     data\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124mEnjoyment\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(title)] \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124mEnjoyment\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(title)]\u001B[38;5;241m.\u001B[39mapply(listify, args\u001B[38;5;241m=\u001B[39m())\n\u001B[1;32m     21\u001B[0m     estr \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m title \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAction\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdventure\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m## Remove data with too few or many points, and exclude those who have the same enjoyments for more than 30 seconds\u001B[39;00m\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m row\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m title \u001B[38;5;129;01min\u001B[39;00m titles:\n\u001B[0;32m---> 20\u001B[0m     data\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124mEnjoyment\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(title)] \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124mEnjoyment\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(title)]\u001B[38;5;241m.\u001B[39mapply(listify, args\u001B[38;5;241m=\u001B[39m())\n\u001B[1;32m     21\u001B[0m     estr \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m title \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAction\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdventure\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m## Remove data with too few or many points, and exclude those who have the same enjoyments for more than 30 seconds\u001B[39;00m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/222.3345.131/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/222.3345.131/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('./data/data_prolific.csv')\n",
    "\n",
    "## Performquad(np.poly1d(np.polyfit(xs, ys_mean, 10)), 0, 100) Exclusions\n",
    "data = data.drop(data[data.Finished != 'True'].index)\n",
    "\n",
    "## All passed at least one of the two attention and comprehension checks\n",
    "## Drop low connections\n",
    "#data = data.drop(data[data.ResponseId == 'R_10ovXcMfOnkIZYm'].index) # ON MTURK DATA\n",
    "\n",
    "lengths = []\n",
    "\n",
    "def listify(row):\n",
    "    row = str(row).split(',')\n",
    "    row = [float(y) for y in row]\n",
    "\n",
    "    return row\n",
    "\n",
    "for title in titles:\n",
    "    data.loc[:, '{}Enjoyment'.format(title)] = data.loc[:, '{}Enjoyment'.format(title)].apply(listify, args=())\n",
    "    estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "\n",
    "## Remove data with too few or many points, and exclude those who have the same enjoyments for more than 30 seconds\n",
    "rms = []\n",
    "for index, row in data.iterrows():\n",
    "    for title in titles:\n",
    "        if abs(len(row['{}Enjoyment'.format(title)]) - 900) > 300:\n",
    "            print(\"Low data qual {}\".format(row['ResponseId']))\n",
    "            print(len(row['{}Enjoyment'.format(title)]))\n",
    "            rms.append(row['ResponseId'])\n",
    "\n",
    "        if max([sum(1 for i in g) for k,g in groupby(row['{}Enjoyment'.format(title)])]) > 300:\n",
    "            print(\"Bigger than 300.. {}\".format(row['ResponseId']))\n",
    "            print(max([sum(1 for i in g) for k,g in groupby(row['{}Enjoyment'.format(title)])]))\n",
    "            rms.append(row['ResponseId'])\n",
    "\n",
    "\n",
    "\n",
    "rms = list(dict.fromkeys(rms))\n",
    "data = data[~data['ResponseId'].isin(rms)]\n",
    "print(rms)\n",
    "print(len(rms))\n",
    "\n",
    "def resample_time(row):\n",
    "    return signal.resample(row, 900)\n",
    "\n",
    "##  Resample the data to be 900 ms, and plot the graphs\n",
    "for title in titles:\n",
    "    data.loc[:, '{}Enjoyment'.format(title)] = data.loc[:, '{}Enjoyment'.format(title)].apply(resample_time)\n",
    "    estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "    plot_lines(data.loc[:, '{}Enjoyment'.format(title)], title='{}'.format(title), wtp_mean=round(data['{}_willing_{}'.format(title.lower(), estr)].astype(int).mean(), 2), wtp_std=round(data['{}_willing_{}'.format(title.lower(), estr)].astype(int).std(), 2), mean=True)\n",
    "\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Calculate metrics for predicting enjoyments...\n",
    "\n",
    "xs = np.linspace(0, 90, num=900)\n",
    "\n",
    "# Number of Peaks\n",
    "def get_num_peaks(row):\n",
    "    poly = np.polyfit(xs, row, 10)\n",
    "    poly_y = np.poly1d(poly)(xs)\n",
    "\n",
    "    peaks, _ = signal.find_peaks(poly_y)\n",
    "\n",
    "    #plot_lines(row, \"asd\", 0, 0)\n",
    "    return len(peaks)\n",
    "\n",
    "# Number of Valleys\n",
    "def get_num_valleys(row):\n",
    "    poly = np.polyfit(xs, row, 10)\n",
    "    poly_y = np.poly1d(poly)(xs)\n",
    "\n",
    "    # Find peaks of negative signal ---\n",
    "    peaks, _ = signal.find_peaks(-poly_y)\n",
    "\n",
    "    #plot_lines(row, \"asd\", 0, 0)\n",
    "    return len(peaks)\n",
    "\n",
    "# Number of Extrema\n",
    "def get_num_extrema(row):\n",
    "    return get_num_peaks(row) + get_num_valleys(row)\n",
    "\n",
    "def get_first_derivative(row):\n",
    "    poly = np.polyfit(xs, row, 10)\n",
    "    return json.dumps(list(np.polyder(poly)))\n",
    "\n",
    "def get_poly(row):\n",
    "    #plot_lines(row, \"asd\", 0, 0)\n",
    "    return json.dumps(list(np.polyfit(xs, row, 10)))\n",
    "\n",
    "## Save the polynomials for R\n",
    "for title in titles:\n",
    "    data[title + '_first_derivative'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_first_derivative)\n",
    "    data[title + '_equation'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_poly)\n",
    "    data[title + '_number_peaks'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_peaks)\n",
    "    data[title + '_number_valleys'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_valleys)\n",
    "    data[title + '_number_extrema'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_extrema)\n",
    "\n",
    "\n",
    "data.to_csv('./data/lifelines_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "################## FLATTEN THE DATA ##################\n",
    "\n",
    "#    Input: dataframe with number of rows = n_subjects\n",
    "#    Output: dataframe with number of rows = n_subjects * n_genres (=8)\n",
    "data = pd.read_csv('./data/lifelines_w_features.csv')\n",
    "include_points = True\n",
    "\n",
    "df = None\n",
    "count = 1\n",
    "\n",
    "def flatten_data(data, count, df, include_points=False):\n",
    "    # Split the columns, based on name\n",
    "    for title in titles:\n",
    "        a = data.filter(regex=(title))\n",
    "        b = data.filter(regex=(title.lower()))\n",
    "\n",
    "        acols = [c for c in a.columns][4:]\n",
    "        bcols = [c for c in b.columns][5:]\n",
    "\n",
    "        a = a[acols]\n",
    "        b = b[bcols]\n",
    "\n",
    "        X = pd.concat([a, b], axis=1)\n",
    "\n",
    "        old_colnames = list(X.columns)\n",
    "        new_colnames = {}\n",
    "\n",
    "        if include_points:\n",
    "            def listify(row):\n",
    "                row = str(row).replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "                row = [float(y) for y in row if y != '']\n",
    "\n",
    "                return row\n",
    "\n",
    "\n",
    "            X['points'] = data['{}Enjoyment'.format(title)]\n",
    "            X.loc[:, 'points'] = X.loc[:, 'points'].apply(listify)\n",
    "\n",
    "        for old in old_colnames:\n",
    "            new_colnames[old] = old.lower().split(title.lower() + \"_\")[1]\n",
    "\n",
    "            if 'willing' in new_colnames[old]:\n",
    "                new_colnames[old] = new_colnames[old][:-2]\n",
    "\n",
    "        X = X.rename(columns = new_colnames)\n",
    "        X['genre'] = title\n",
    "\n",
    "        X['subject'] = [c for c in range(1, data.shape[0] + 1)]\n",
    "        X['movie_choice'] = data['movie_choice']\n",
    "        count += 1\n",
    "\n",
    "\n",
    "        if df is None:\n",
    "            df = copy.deepcopy(X)\n",
    "        else:\n",
    "            df = pd.concat([df, X], axis=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = flatten_data(data, count, df, include_points)\n",
    "df = df.sort_values(by=['subject', 'genre'])\n",
    "\n",
    "def get_token(row):\n",
    "    return [token.pos_ for token in nlp(row)][0]\n",
    "\n",
    "def get_tokens_sentences(row):\n",
    "    return [token.pos_ for token in nlp(row)]\n",
    "\n",
    "df.loc[:, 'word_tag'] = df.loc[:, 'word'].apply(get_token)\n",
    "\n",
    "if include_points:\n",
    "    df.to_csv('./data/data_long.csv')\n",
    "else:\n",
    "    df.to_csv('./data/data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "################## PLOTTING ##################\n",
    "\n",
    "# Plot each participant separately\n",
    "\n",
    "plots = {}\n",
    "\n",
    "for title in titles:\n",
    "    count = 1\n",
    "    for index, row in data.iterrows():\n",
    "        plot_lines(row['{}Enjoyment'.format(title)], str(count) + \"_{}\".format(title), wtp_mean=row.filter(regex='{}_willing'.format(title).lower())[0], wtp_std=None, word=row.filter(regex='{}_word'.format(title).lower())[0])\n",
    "        count += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Concatenate vertically\n",
    "def get_concat_v(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatenate horizontally\n",
    "def get_concat_h(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatanate all participant plots into one huge plot\n",
    "himg2 = None\n",
    "for title in titles:\n",
    "    im2 = None\n",
    "    for i in range(1, 234):\n",
    "        img_file = glob.glob('./plots/individual/lifeline_{}_{}.png'.format(i, title))[0]\n",
    "        print(img_file)\n",
    "        im2 = get_concat_v(Image.open(img_file), im2)\n",
    "\n",
    "    im2.save(\"{}_combined.jpg\".format(title))\n",
    "    himg2 = get_concat_h(im2, himg2)\n",
    "\n",
    "himg2.save(\"all_combined.jpg\".format(title))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ba5ede13f0387f51f50b72b517e398c81deb77e749ad9440ae5ea50ce01832d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}