{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Lifelines\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from itertools import groupby\n",
    "import spacy\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', np.RankWarning)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "titles = ['Horror', 'Adventure', 'Drama', 'Biography', 'Action', 'Fantasy', 'SciFi', 'Animation']\n",
    "fit_degree = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_lines(ys, title, wtp_mean, wtp_std, mean=False, word=None):\n",
    "    if mean:\n",
    "        ys_mean = np.stack(ys).mean(axis=0)\n",
    "        ys_sem = sem(np.stack(ys), axis=0)\n",
    "    else:\n",
    "        ys_mean = ys\n",
    "\n",
    "    xs = np.linspace(0, 90, num=900)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    n_lines = 15\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, n_lines + 2)))\n",
    "    colors = []\n",
    "\n",
    "    for i in range(1, n_lines + 2):\n",
    "        colors.append(next(color))\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(1, n_lines):\n",
    "        fit = np.poly1d(np.polyfit(xs, ys_mean, 10 * i))(xs)\n",
    "        if np.max(fit) > 200:\n",
    "            print(\"VALUE TOO HIGH!!!\")\n",
    "\n",
    "        if np.min(fit) > 200:\n",
    "            print(\"VALUE TOO LOW!!!\")\n",
    "\n",
    "        plt.plot(xs, fit, color=colors[i - 1],\n",
    "                 label=\"Degree {}\".format(str(10 * i)))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    plt.plot(xs, ys_mean, color=colors[n_lines], label=\"Original\")\n",
    "\n",
    "    if mean:\n",
    "        plt.fill_between(xs, ys_mean - ys_sem, ys_mean + ys_sem, alpha=0.2)\n",
    "\n",
    "    plt.title(\"Enjoyment of {} Movie Trailer Over Time\\nWTP M={}, SD={}\".format(title, str(wtp_mean), str(wtp_std)), )\n",
    "\n",
    "    if wtp_std is None:\n",
    "        plt.title(\"WTP = {}, Word = {}\".format(str(wtp_mean), word), fontsize=25)\n",
    "    else:\n",
    "        plt.ylabel(\"Enjoyment\")\n",
    "        plt.xlabel(\"Time (sec)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    if wtp_std is None:\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        plt.savefig(\"./plots/individual/lifeline_{}.png\".format(title), dpi=50)\n",
    "    else:\n",
    "        plt.savefig(\"./plots/analysis_plots/lifeline_{}.png\".format(title), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rpy2 import robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr('base')\n",
    "stats = importr('stats')\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "data = pd.read_csv('./data/data_prolific.csv')\n",
    "data = data.drop(data[data.Finished != 'True'].index)\n",
    "\n",
    "## All passed at least one of the two attention and comprehension checks\n",
    "## Drop low connections\n",
    "\n",
    "lengths = []\n",
    "\n",
    "\n",
    "def listify(row):\n",
    "    row = str(row).split(',')\n",
    "    row = [float(y) for y in row]\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "for title in titles:\n",
    "    data.loc[:, '{}Enjoyment'.format(title)] = data.loc[:, '{}Enjoyment'.format(title)].apply(listify, args=())\n",
    "    estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "\n",
    "######################## PERFORM EXCLUSIONS ########################\n",
    "# All passed attention checks\n",
    "# Comprehension checks\n",
    "total = data.shape[0]\n",
    "data = data[(data['comp_check_1'] == 'Shazam! Fury of the Gods') & (data['comp_check_2'] == 'Enjoyment')]\n",
    "print(\"Number of comprehension exclusions: \", total - data.shape[0])\n",
    "\n",
    "## Remove data with too few or many points, and exclude those who have the same enjoyments for more than 30 seconds\n",
    "rms = []\n",
    "for index, row in data.iterrows():\n",
    "    for title in titles:\n",
    "        if abs(len(row['{}Enjoyment'.format(title)]) - 900) > 300:\n",
    "            print(\"Low data qual {}\".format(row['ResponseId']))\n",
    "            print(len(row['{}Enjoyment'.format(title)]))\n",
    "            rms.append(row['ResponseId'])\n",
    "\n",
    "        if max([sum(1 for i in g) for k, g in groupby(row['{}Enjoyment'.format(title)])]) > 300:\n",
    "            print(\"Bigger than 300.. {}\".format(row['ResponseId']))\n",
    "            print(max([sum(1 for i in g) for k, g in groupby(row['{}Enjoyment'.format(title)])]))\n",
    "            rms.append(row['ResponseId'])\n",
    "\n",
    "        # Get the duration of which resolution the participant watched the video in\n",
    "        state_changes = json.loads(row['{}StateChanges'.format(title)])\n",
    "        playback_qualities = json.loads(row['{}PlaybackQualities'.format(title)])\n",
    "\n",
    "        data.loc[index, '{}PlaybackQuality'.format(title)] = playback_qualities[0][0]\n",
    "        data.loc[index, '{}StateChangeAmount'.format(title)] = len(state_changes)\n",
    "        data.loc[index, '{}QualityChangeAmount'.format(title)] = len(playback_qualities)\n",
    "\n",
    "rms = list(dict.fromkeys(rms))\n",
    "data = data[~data['ResponseId'].isin(rms)]\n",
    "print(rms)\n",
    "print(\"Exclusions from inactivity: \", len(rms))\n",
    "\n",
    "\n",
    "def resample_time(row):\n",
    "    return signal.resample(row, 900)\n",
    "\n",
    "\n",
    "##  Resample the data to be 900 ms, and plot the graphs\n",
    "for title in titles:\n",
    "    data.loc[:, '{}Enjoyment'.format(title)] = data.loc[:, '{}Enjoyment'.format(title)].apply(resample_time)\n",
    "    estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "    plot_lines(data.loc[:, '{}Enjoyment'.format(title)], title='{}'.format(title),\n",
    "               wtp_mean=round(data['{}_willing_{}'.format(title.lower(), estr)].astype(int).mean(), 2),\n",
    "               wtp_std=round(data['{}_willing_{}'.format(title.lower(), estr)].astype(int).std(), 2), mean=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Linear regression to see whether different playback qualities and state changes affect WTP\n",
    "for title in titles:\n",
    "    print(title, \"State Change Amount\")\n",
    "\n",
    "    estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "    robjects.globalenv['dataframe'] = data[\n",
    "        ['{}_willing_{}'.format(title.lower(), estr), '{}StateChangeAmount'.format(title),\n",
    "         '{}PlaybackQuality'.format(title), '{}QualityChangeAmount'.format(title)]]\n",
    "    M = stats.lm(\n",
    "        '{}_willing_{} ~ {}StateChangeAmount + {}QualityChangeAmount + {}PlaybackQuality'.format(title.lower(), estr,\n",
    "                                                                                                 title, title, title),\n",
    "        data=base.as_symbol('dataframe'))\n",
    "    print(base.summary(M))\n",
    "\n",
    "    # Clean dataframe since we do not need these columns now\n",
    "    data = data.drop(columns=['{}StateChangeAmount'.format(title), '{}QualityChangeAmount'.format(title),\n",
    "                              '{}PlaybackQuality'.format(title)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from scipy.stats import sem\n",
    "\n",
    "################ Calculate metrics for predicting enjoyments\n",
    "xs = np.linspace(0, 90, num=900)\n",
    "\n",
    "\n",
    "# Number of Peaks\n",
    "def get_num_peaks(row):\n",
    "    poly = np.polyfit(xs, row, fit_degree)\n",
    "    poly_y = np.poly1d(poly)(xs)\n",
    "\n",
    "    peaks, _ = signal.find_peaks(poly_y)\n",
    "    return len(peaks)\n",
    "\n",
    "\n",
    "# Number of Valleys\n",
    "def get_num_valleys(row):\n",
    "    poly = np.polyfit(xs, row, fit_degree)\n",
    "    poly_y = np.poly1d(poly)(xs)\n",
    "\n",
    "    # Find peaks of negative signal ---\n",
    "    peaks, _ = signal.find_peaks(-poly_y)\n",
    "\n",
    "    return len(peaks)\n",
    "\n",
    "\n",
    "# Number of Extrema\n",
    "def get_num_extrema(row):\n",
    "    return get_num_peaks(row) + get_num_valleys(row)\n",
    "\n",
    "\n",
    "def get_first_derivative(row):\n",
    "    poly = np.polyfit(xs, row, fit_degree)\n",
    "    return json.dumps(list(np.polyder(poly)))\n",
    "\n",
    "\n",
    "def get_poly(row):\n",
    "    return json.dumps(list(np.polyfit(xs, row, fit_degree)))\n",
    "\n",
    "\n",
    "def get_best_degree(row, errors):\n",
    "    for degree in range(1, 150):\n",
    "        if errors.get(degree, None) is None:\n",
    "            errors[degree] = []\n",
    "\n",
    "        #plot_lines(row, \"testing_{}\".format(np.mean(row)), 10, 0)\n",
    "        fit = np.polyfit(xs, row, degree)\n",
    "        yfit = np.polyval(fit, xs)\n",
    "        residual = np.sum((row - yfit) ** 2)\n",
    "        errors[degree].append(residual)\n",
    "        #errors[degree].append(np.sum(fit[1]))\n",
    "\n",
    "\n",
    "\n",
    "errors = {}\n",
    "## Save the polynomials for R\n",
    "for title in titles:\n",
    "    print(title)\n",
    "    data.loc[:, '{}Enjoyment'.format(title)].apply(get_best_degree, errors=errors)\n",
    "    data[title + '_first_derivative'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_first_derivative)\n",
    "    data[title + '_equation'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_poly)\n",
    "    data[title + '_number_peaks'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_peaks)\n",
    "    data[title + '_number_valleys'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_valleys)\n",
    "    data[title + '_number_extrema'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_extrema)\n",
    "\n",
    "data.to_csv('./data/lifelines_cleaned_deg{}.csv'.format(fit_degree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Convert cluster centers to polynomials\n",
    "\n",
    "def get_poly(row, i):\n",
    "    plot_lines(row, \"cluster_{}_{}\".format(i, np.mean(row)), 0, 0)\n",
    "    xs = np.linspace(0, 90, num=900)\n",
    "    return json.dumps(list(np.polyfit(xs, row, fit_degree)))\n",
    "\n",
    "cluster_centers = pd.read_csv('./data/cluster_centers.csv')\n",
    "cluster_polynomials = {}\n",
    "\n",
    "for i in range(0, 27):\n",
    "    cluster_polynomials[i] = get_poly(np.asarray(cluster_centers[str(i)]), i)\n",
    "    print(i)\n",
    "\n",
    "print(cluster_polynomials)\n",
    "cp_pd = pd.DataFrame.from_dict(cluster_polynomials, orient='index')\n",
    "cp_pd.to_csv('./data/cluster_polynomials.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "err_mean = []\n",
    "err_sem = []\n",
    "for degree, errs in errors.items():\n",
    "    print(\"Error for degree {} is: \".format(degree), sum(errs) / len(errs))\n",
    "    err_mean.append(sum(errs) / len(errs))\n",
    "    err_sem.append(sem(errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min(err_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_error_line(err_mean, err_sem):\n",
    "    SMALL_SIZE = 16 * 9/10\n",
    "    MEDIUM_SIZE = 20 * 9/10\n",
    "    BIGGER_SIZE = 24 * 9/10\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE + 1)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "    xs = np.linspace(1, 149, num=149)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(xs, err_mean, color=\"#4287f5\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.xlabel(\"Degree\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.savefig(\"./plots/err.png\", dpi=1000)\n",
    "\n",
    "def plot_mean_f1():\n",
    "    SMALL_SIZE = 16 * 9/10\n",
    "    MEDIUM_SIZE = 20 * 9/10\n",
    "    BIGGER_SIZE = 24 * 9/10\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE + 1)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "    xs = np.linspace(2, 30, num=29)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(xs, [0.2705967, 0.2630683, 0.2690001, 0.2686351, 0.2694201, 0.2678952, 0.2694755, 0.2682980, 0.2686308, 0.2678497, 0.2688509, 0.2685838, 0.2684185, 0.2674810, 0.2679320, 0.2658887, 0.2706990, 0.2691831, 0.2659590, 0.2668070, 0.2672212, 0.2686524, 0.2681497, 0.2677279, 0.2687104, 0.2659561, 0.2681775, 0.2643083, 0.2659397], color=\"#4287f5\")\n",
    "\n",
    "    plt.ylabel(\"Overall F1 Score\")\n",
    "    plt.xlabel(\"k\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.savefig(\"./plots/err_kfold.png\", dpi=1000)\n",
    "\n",
    "plot_mean_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################## FLATTEN THE DATA ##################\n",
    "########### Run after running \"calculate_predictors.R ###########\n",
    "#    Input: dataframe with number of rows = n_subjects\n",
    "#    Output: dataframe with number of rows = n_subjects * n_genres (=8)\n",
    "data = pd.read_csv('./data/lifelines_w_features.csv')\n",
    "include_points = True\n",
    "\n",
    "df = None\n",
    "count = 1\n",
    "\n",
    "\n",
    "def flatten_data(data, count, df, include_points=False):\n",
    "    # Split the columns, based on name\n",
    "    for title in titles:\n",
    "        a = data.filter(regex=(title))\n",
    "        b = data.filter(regex=(title.lower()))\n",
    "\n",
    "        acols = [c for c in a.columns][4:]\n",
    "        bcols = [c for c in b.columns][5:]\n",
    "\n",
    "        a = a[acols]\n",
    "        b = b[bcols]\n",
    "\n",
    "        X = pd.concat([a, b], axis=1)\n",
    "\n",
    "        old_colnames = list(X.columns)\n",
    "        new_colnames = {}\n",
    "\n",
    "        if include_points:\n",
    "            def listify(row):\n",
    "                row = str(row).replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "                row = [float(y) for y in row if y != '']\n",
    "\n",
    "                return row\n",
    "\n",
    "            X['points'] = data['{}Enjoyment'.format(title)]\n",
    "            X.loc[:, 'points'] = X.loc[:, 'points'].apply(listify)\n",
    "\n",
    "        for old in old_colnames:\n",
    "            new_colnames[old] = old.lower().split(title.lower() + \"_\")[1]\n",
    "\n",
    "            if 'willing' in new_colnames[old]:\n",
    "                new_colnames[old] = new_colnames[old][:-2]\n",
    "\n",
    "        X = X.rename(columns=new_colnames)\n",
    "        X['genre'] = title\n",
    "\n",
    "        X['subject'] = [c for c in range(1, data.shape[0] + 1)]\n",
    "        X['movie_choice'] = data['movie_choice']\n",
    "        count += 1\n",
    "\n",
    "        if df is None:\n",
    "            df = copy.deepcopy(X)\n",
    "        else:\n",
    "            df = pd.concat([df, X], axis=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = flatten_data(data, count, df, include_points)\n",
    "df = df.sort_values(by=['subject', 'genre'])\n",
    "\n",
    "\n",
    "def get_token(row):\n",
    "    return [token.pos_ for token in nlp(row)][0]\n",
    "\n",
    "\n",
    "def get_tokens_sentences(row):\n",
    "    return [token.pos_ for token in nlp(row)]\n",
    "\n",
    "\n",
    "df.loc[:, 'word_tag'] = df.loc[:, 'word'].apply(get_token)\n",
    "\n",
    "if include_points:\n",
    "    df.to_csv('./data/data_long.csv')\n",
    "else:\n",
    "    df.to_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################## PLOTTING ALL PARTICIPANTS ##################\n",
    "\n",
    "# Plot each participant separately\n",
    "\n",
    "plots = {}\n",
    "\n",
    "for title in titles:\n",
    "    count = 1\n",
    "    for index, row in data.iterrows():\n",
    "        plot_lines(row['{}Enjoyment'.format(title)], str(count) + \"_{}\".format(title),\n",
    "                   wtp_mean=row.filter(regex='{}_willing'.format(title).lower())[0], wtp_std=None,\n",
    "                   word=row.filter(regex='{}_word'.format(title).lower())[0])\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate vertically\n",
    "def get_concat_v(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatenate horizontally\n",
    "def get_concat_h(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatanate all participant plots into one huge plot\n",
    "himg2 = None\n",
    "for title in ['Horror']:\n",
    "    im2 = None\n",
    "    for i in range(1, 234):\n",
    "        img_file = glob.glob('./plots/individual/lifeline_{}_{}.png'.format(i, title))[0]\n",
    "        print(img_file)\n",
    "        im2 = get_concat_v(Image.open(img_file), im2)\n",
    "\n",
    "    im2.save(\"{}_combined.jpg\".format(title))\n",
    "    himg2 = get_concat_h(im2, himg2)\n",
    "\n",
    "himg2.save(\"all_combined.jpg\".format(title))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ba5ede13f0387f51f50b72b517e398c81deb77e749ad9440ae5ea50ce01832d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}